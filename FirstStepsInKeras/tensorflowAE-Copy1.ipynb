{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-4-3a0706bbc7af>:45: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Training...\n",
      "  step, loss =      0:  0.722\n",
      "  step, loss =   1000:  0.262\n",
      "  step, loss =   2000:  0.245\n",
      "  step, loss =   3000:  0.239\n",
      "  step, loss =   4000:  0.235\n",
      "  step, loss =   5000:  0.209\n",
      "  step, loss =   6000:  0.204\n",
      "  step, loss =   7000:  0.194\n",
      "  step, loss =   8000:  0.192\n",
      "  step, loss =   9000:  0.181\n",
      "  step, loss =  10000:  0.180\n",
      "loss (test) =  0.17894478\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   mnist_ae1.py   date. 7/4/2016\n",
    "#   \n",
    "#   Autoencoder tutorial code\n",
    "#\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Variables\n",
    "x = tf.placeholder(\"float\", [None, 784])\n",
    "y_ = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "w_enc = tf.Variable(tf.random_normal([784, 625], mean=0.0, stddev=0.05))\n",
    "w_dec = tf.Variable(tf.random_normal([625, 784], mean=0.0, stddev=0.05))\n",
    "# w_dec = tf.transpose(w_enc) # if you use tied weights\n",
    "b_enc = tf.Variable(tf.zeros([625]))\n",
    "b_dec = tf.Variable(tf.zeros([784]))\n",
    "\n",
    "# Create the model\n",
    "def model(X, w_e, b_e, w_d, b_d):\n",
    "    encoded = tf.sigmoid(tf.matmul(X, w_e) + b_e)\n",
    "    decoded = tf.sigmoid(tf.matmul(encoded, w_d) + b_d)\n",
    "    \n",
    "    return encoded, decoded\n",
    "\n",
    "encoded, decoded = model(x, w_enc, b_enc, w_dec, b_dec)\n",
    "\n",
    "# Cost Function basic term\n",
    "cross_entropy = -1. * x * tf.log(decoded) - (1. - x) * tf.log(1. - decoded)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "train_step = tf.train.AdagradOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# Train\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('Training...')\n",
    "    for i in range(10001):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(128)\n",
    "        train_step.run({x: batch_xs, y_: batch_ys})\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            train_loss = loss.eval({x: batch_xs, y_: batch_ys})\n",
    "            print('  step, loss = %6d: %6.3f' % (i, train_loss))\n",
    "        \n",
    "    # generate decoded image with test data\n",
    "    test_fd = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "    decoded_imgs = decoded.eval(test_fd)\n",
    "    print('loss (test) = ', loss.eval(test_fd))\n",
    "    \n",
    "x_test = mnist.test.images\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.savefig('mnist_ae1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
