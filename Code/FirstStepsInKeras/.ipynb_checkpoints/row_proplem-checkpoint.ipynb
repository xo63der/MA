{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:382: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:384: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:386: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Conv2D' object has no attribute 'nb_row'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e5b72e93cb63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[0mc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[0mu1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m \u001b[0md1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D_tied\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtied_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# now this layer is tied to conv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;31m# and compile as usual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-e5b72e93cb63>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, nb_filter, nb_row, nb_col, init, activation, weights, border_mode, subsample, dim_ordering, W_regularizer, b_regularizer, activity_regularizer, W_constraint, b_constraint, bias, tied_to, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtied_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtied_to\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_filter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtied_to\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_row\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtied_to\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_col\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Conv2D' object has no attribute 'nb_row'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras import activations, initializers, regularizers, constraints\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "from keras.layers import Convolution1D, Convolution2D, Input, MaxPooling2D, UpSampling2D\n",
    "import tensorflow as tf\n",
    "\n",
    "class Convolution1D_tied(Layer):\n",
    "    '''Convolution operator for filtering neighborhoods of one-dimensional inputs.\n",
    "    When using this layer as the first layer in a model,\n",
    "    either provide the keyword argument `input_dim`\n",
    "    (int, e.g. 128 for sequences of 128-dimensional vectors),\n",
    "    or `input_shape` (tuple of integers, e.g. (10, 128) for sequences\n",
    "    of 10 vectors of 128-dimensional vectors).\n",
    "    # Example\n",
    "    ```python\n",
    "        # apply a convolution 1d of length 3 to a sequence with 10 timesteps,\n",
    "        # with 64 output filters\n",
    "        model = Sequential()\n",
    "        model.add(Convolution1D(64, 3, border_mode='same', input_shape=(10, 32)))\n",
    "        # now model.output_shape == (None, 10, 64)\n",
    "        # add a new conv1d on top\n",
    "        model.add(Convolution1D(32, 3, border_mode='same'))\n",
    "        # now model.output_shape == (None, 10, 32)\n",
    "    ```\n",
    "    # Arguments\n",
    "        nb_filter: Number of convolution kernels to use\n",
    "            (dimensionality of the output).\n",
    "        filter_length: The extension (spatial or temporal) of each filter.\n",
    "        init: name of initialization function for the weights of the layer\n",
    "            (see [initializers](../initializers.md)),\n",
    "            or alternatively, Theano function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "        activation: name of activation function to use\n",
    "            (see [activations](../activations.md)),\n",
    "            or alternatively, elementwise Theano function.\n",
    "            If you don't specify anything, no activation is applied\n",
    "            (ie. \"linear\" activation: a(x) = x).\n",
    "        weights: list of numpy arrays to set as initial weights.\n",
    "        border_mode: 'valid' or 'same'.\n",
    "        subsample_length: factor by which to subsample output.\n",
    "        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n",
    "            (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n",
    "            applied to the bias.\n",
    "        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n",
    "            applied to the network output.\n",
    "        W_constraint: instance of the [constraints](../constraints.md) module\n",
    "            (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "        b_constraint: instance of the [constraints](../constraints.md) module,\n",
    "            applied to the bias.\n",
    "        bias: whether to include a bias\n",
    "            (i.e. make the layer affine rather than linear).\n",
    "        input_dim: Number of channels/dimensions in the input.\n",
    "            Either this argument or the keyword argument `input_shape`must be\n",
    "            provided when using this layer as the first layer in a model.\n",
    "        input_length: Length of input sequences, when it is constant.\n",
    "            This argument is required if you are going to connect\n",
    "            `Flatten` then `Dense` layers upstream\n",
    "            (without it, the shape of the dense outputs cannot be computed).\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, input_dim)`.\n",
    "    # Output shape\n",
    "        3D tensor with shape: `(samples, new_steps, nb_filter)`.\n",
    "        `steps` value might have changed due to padding.\n",
    "    '''\n",
    "    def __init__(self, nb_filter, filter_length,\n",
    "                 init='uniform', activation='linear', weights=None,\n",
    "                 border_mode='valid', subsample_length=1,\n",
    "                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, input_dim=None, input_length=None, tied_to=None,\n",
    "                 **kwargs):\n",
    "\n",
    "        if border_mode not in {'valid', 'same'}:\n",
    "            raise Exception('Invalid border mode for Convolution1D:', border_mode)\n",
    "\n",
    "        self.tied_to = tied_to\n",
    "        self.nb_filter = nb_filter #TODO may have to change this and the one below...\n",
    "        self.filter_length = tied_to.filter_length\n",
    "        self.init = initializers.get(init, dim_ordering='th')\n",
    "        self.activation = activations.get(activation)\n",
    "        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'\n",
    "        self.border_mode = border_mode\n",
    "        self.subsample_length = subsample_length\n",
    "\n",
    "        self.subsample = (subsample_length, 1)\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        self.initial_weights = tied_to.initial_weights\n",
    "        self.input_dim = input_dim\n",
    "        self.input_length = input_length\n",
    "        if self.input_dim:\n",
    "            kwargs['input_shape'] = (self.input_length, self.input_dim)\n",
    "        super(Convolution1D_tied, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_dim = input_shape[2]\n",
    "        # self.W_shape = (self.nb_filter, input_dim, self.filter_length, 1)\n",
    "        # self.W = self.init(self.W_shape, name='{}_W'.format(self.name))\n",
    "        if self.bias:\n",
    "            self.b = K.zeros((self.nb_filter,), name='{}_b'.format(self.name))\n",
    "            self.trainable_weights = [self.b]\n",
    "        # else:\n",
    "        #     self.trainable_weights = [self.W]\n",
    "        self.regularizers = []\n",
    "        #\n",
    "        # if self.W_regularizer:\n",
    "        #     self.W_regularizer.set_param(self.W)\n",
    "        #     self.regularizers.append(self.W_regularizer)\n",
    "        #\n",
    "        if self.bias and self.b_regularizer:\n",
    "            self.b_regularizer.set_param(self.b)\n",
    "            self.regularizers.append(self.b_regularizer)\n",
    "        #\n",
    "        # if self.activity_regularizer:\n",
    "        #     self.activity_regularizer.set_layer(self)\n",
    "        #     self.regularizers.append(self.activity_regularizer)\n",
    "        #\n",
    "        # self.constraints = {}\n",
    "        # if self.W_constraint:\n",
    "        #     self.constraints[self.W] = self.W_constraint\n",
    "        if self.bias and self.b_constraint:\n",
    "            self.constraints[self.b] = self.b_constraint\n",
    "        #\n",
    "        # if self.initial_weights is not None:\n",
    "        #     self.set_weights(self.initial_weights)\n",
    "        #     del self.initial_weights\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        length = conv_output_length(input_shape[1],\n",
    "                                    self.filter_length,\n",
    "                                    self.border_mode,\n",
    "                                    self.subsample[0])\n",
    "        return (input_shape[0], length, self.nb_filter)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        x = K.expand_dims(x, -1)  # add a dimension of the right\n",
    "        x = K.permute_dimensions(x, (0, 2, 1, 3))\n",
    "\n",
    "        # TF uses the last dimension as channel dimension,\n",
    "        # instead of the 2nd one.\n",
    "        # TH kernel shape: (depth, input_depth, rows, cols)\n",
    "        # TF kernel shape: (rows, cols, input_depth, depth)\n",
    "\n",
    "        # for us, we need to switch the rows with the columns?\n",
    "        W = tf.transpose(self.tied_to.W, (1, 0, 2, 3))\n",
    "        output = K.conv2d(x, W, strides=self.subsample,\n",
    "                          border_mode=self.border_mode,\n",
    "                          dim_ordering='th')\n",
    "        if self.bias:\n",
    "            output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n",
    "        output = K.squeeze(output, 3)  # remove the dummy 3rd dimension\n",
    "        output = K.permute_dimensions(output, (0, 2, 1))\n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'nb_filter': self.nb_filter,\n",
    "                  'filter_length': self.filter_length,\n",
    "                  'init': self.init.__name__,\n",
    "                  'activation': self.activation.__name__,\n",
    "                  'border_mode': self.border_mode,\n",
    "                  'subsample_length': self.subsample_length,\n",
    "                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n",
    "                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n",
    "                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n",
    "                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n",
    "                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n",
    "                  'bias': self.bias,\n",
    "                  'input_dim': self.input_dim,\n",
    "                  'input_length': self.input_length}\n",
    "        base_config = super(Convolution1D_tied, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Convolution2D_tied(Layer):\n",
    "    '''Convolution operator for filtering windows of two-dimensional inputs.\n",
    "    When using this layer as the first layer in a model,\n",
    "    provide the keyword argument `input_shape`\n",
    "    (tuple of integers, does not include the sample axis),\n",
    "    e.g. `input_shape=(3, 128, 128)` for 128x128 RGB pictures.\n",
    "    # Examples\n",
    "    ```python\n",
    "        # apply a 3x3 convolution with 64 output filters on a 256x256 image:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3, 256, 256)))\n",
    "        # now model.output_shape == (None, 64, 256, 256)\n",
    "        # add a 3x3 convolution on top, with 32 output filters:\n",
    "        model.add(Convolution2D(32, 3, 3, border_mode='same'))\n",
    "        # now model.output_shape == (None, 32, 256, 256)\n",
    "    ```\n",
    "    # Arguments\n",
    "        nb_filter: Number of convolution filters to use.\n",
    "        nb_row: Number of rows in the convolution kernel.\n",
    "        nb_col: Number of columns in the convolution kernel.\n",
    "        init: name of initialization function for the weights of the layer\n",
    "            (see [initializers](../initializers.md)), or alternatively,\n",
    "            Theano function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass\n",
    "            a `weights` argument.\n",
    "        activation: name of activation function to use\n",
    "            (see [activations](../activations.md)),\n",
    "            or alternatively, elementwise Theano function.\n",
    "            If you don't specify anything, no activation is applied\n",
    "            (ie. \"linear\" activation: a(x) = x).\n",
    "        weights: list of numpy arrays to set as initial weights.\n",
    "        border_mode: 'valid' or 'same'.\n",
    "        subsample: tuple of length 2. Factor by which to subsample output.\n",
    "            Also called strides elsewhere.\n",
    "        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n",
    "            (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n",
    "            applied to the bias.\n",
    "        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n",
    "            applied to the network output.\n",
    "        W_constraint: instance of the [constraints](../constraints.md) module\n",
    "            (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "        b_constraint: instance of the [constraints](../constraints.md) module,\n",
    "            applied to the bias.\n",
    "        dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension\n",
    "            (the depth) is at index 1, in 'tf' mode is it at index 3.\n",
    "            It defaults to the `image_dim_ordering` value found in your\n",
    "            Keras config file at `~/.keras/keras.json`.\n",
    "            If you never set it, then it will be \"th\".\n",
    "        bias: whether to include a bias\n",
    "            (i.e. make the layer affine rather than linear).\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(samples, channels, rows, cols)` if dim_ordering='th'\n",
    "        or 4D tensor with shape:\n",
    "        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n",
    "    # Output shape\n",
    "        4D tensor with shape:\n",
    "        `(samples, nb_filter, new_rows, new_cols)` if dim_ordering='th'\n",
    "        or 4D tensor with shape:\n",
    "        `(samples, new_rows, new_cols, nb_filter)` if dim_ordering='tf'.\n",
    "        `rows` and `cols` values might have changed due to padding.\n",
    "    '''\n",
    "    def __init__(self, nb_filter, nb_row, nb_col,\n",
    "                 init='glorot_uniform', activation='linear', weights=None,\n",
    "                 border_mode='valid', subsample=(1, 1), dim_ordering='default',\n",
    "                 W_regularizer=None, b_regularizer=None, activity_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, tied_to=None, **kwargs):\n",
    "        if dim_ordering == 'default':\n",
    "            dim_ordering = K.image_dim_ordering()\n",
    "        if border_mode not in {'valid', 'same'}:\n",
    "            raise Exception('Invalid border mode for Convolution2D:', border_mode)\n",
    "        self.tied_to = tied_to\n",
    "        self.nb_filter = nb_filter\n",
    "        self.nb_row = tied_to.nb_row\n",
    "        self.nb_col = tied_to.nb_col\n",
    "        self.init = initializers.get(init, dim_ordering=dim_ordering)\n",
    "        self.activation = activations.get(activation)\n",
    "        assert border_mode in {'valid', 'same'}, 'border_mode must be in {valid, same}'\n",
    "        self.border_mode = border_mode\n",
    "        self.subsample = tuple(subsample)\n",
    "        assert dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n",
    "        self.dim_ordering = dim_ordering\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        self.initial_weights = tied_to.initial_weights\n",
    "        super(Convolution2D_tied, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.dim_ordering == 'th':\n",
    "            stack_size = input_shape[1]\n",
    "            self.W_shape = (self.nb_filter, stack_size, self.nb_row, self.nb_col)\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            stack_size = input_shape[3]\n",
    "            self.W_shape = (self.nb_row, self.nb_col, stack_size, self.nb_filter)\n",
    "        else:\n",
    "            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n",
    "        # self.W = self.init(self.W_shape, name='{}_W'.format(self.name))\n",
    "        if self.bias:\n",
    "            self.b = K.zeros((self.nb_filter,), name='{}_b'.format(self.name))\n",
    "            self.trainable_weights = [self.b]\n",
    "        # else:\n",
    "        #     self.trainable_weights = [self.W]\n",
    "        self.regularizers = []\n",
    "\n",
    "        # if self.W_regularizer:\n",
    "        #     self.W_regularizer.set_param(self.W)\n",
    "        #     self.regularizers.append(self.W_regularizer)\n",
    "\n",
    "        if self.bias and self.b_regularizer:\n",
    "            self.b_regularizer.set_param(self.b)\n",
    "            self.regularizers.append(self.b_regularizer)\n",
    "\n",
    "        if self.activity_regularizer:\n",
    "            self.activity_regularizer.set_layer(self)\n",
    "            self.regularizers.append(self.activity_regularizer)\n",
    "\n",
    "        self.constraints = {}\n",
    "        # if self.W_constraint:\n",
    "        #     self.constraints[self.W] = self.W_constraint\n",
    "        if self.bias and self.b_constraint:\n",
    "            self.constraints[self.b] = self.b_constraint\n",
    "\n",
    "        # if self.initial_weights is not None:\n",
    "        #     self.set_weights(self.initial_weights)\n",
    "        #     del self.initial_weights\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        if self.dim_ordering == 'th':\n",
    "            rows = input_shape[2]\n",
    "            cols = input_shape[3]\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            rows = input_shape[1]\n",
    "            cols = input_shape[2]\n",
    "        else:\n",
    "            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n",
    "\n",
    "        rows = conv_output_length(rows, self.nb_row,\n",
    "                                  self.border_mode, self.subsample[0])\n",
    "        cols = conv_output_length(cols, self.nb_col,\n",
    "                                  self.border_mode, self.subsample[1])\n",
    "\n",
    "        if self.dim_ordering == 'th':\n",
    "            return (input_shape[0], self.nb_filter, rows, cols)\n",
    "        elif self.dim_ordering == 'tf':\n",
    "            return (input_shape[0], rows, cols, self.nb_filter)\n",
    "        else:\n",
    "            raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        W = tf.transpose(self.tied_to.W, (1, 0, 2, 3))\n",
    "        output = K.conv2d(x, W, strides=self.subsample,\n",
    "                          border_mode=self.border_mode,\n",
    "                          dim_ordering=self.dim_ordering,\n",
    "                          filter_shape=self.W_shape)\n",
    "        if self.bias:\n",
    "            if self.dim_ordering == 'th':\n",
    "                output += K.reshape(self.b, (1, self.nb_filter, 1, 1))\n",
    "            elif self.dim_ordering == 'tf':\n",
    "                output += K.reshape(self.b, (1, 1, 1, self.nb_filter))\n",
    "            else:\n",
    "                raise Exception('Invalid dim_ordering: ' + self.dim_ordering)\n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'nb_filter': self.nb_filter,\n",
    "                  'nb_row': self.nb_row,\n",
    "                  'nb_col': self.nb_col,\n",
    "                  'init': self.init.__name__,\n",
    "                  'activation': self.activation.__name__,\n",
    "                  'border_mode': self.border_mode,\n",
    "                  'subsample': self.subsample,\n",
    "                  'dim_ordering': self.dim_ordering,\n",
    "                  'W_regularizer': self.W_regularizer.get_config() if self.W_regularizer else None,\n",
    "                  'b_regularizer': self.b_regularizer.get_config() if self.b_regularizer else None,\n",
    "                  'activity_regularizer': self.activity_regularizer.get_config() if self.activity_regularizer else None,\n",
    "                  'W_constraint': self.W_constraint.get_config() if self.W_constraint else None,\n",
    "                  'b_constraint': self.b_constraint.get_config() if self.b_constraint else None,\n",
    "                  'bias': self.bias}\n",
    "        base_config = super(Convolution2D_tied, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "\n",
    "input_img = Input(shape=(1, 28, 28))\n",
    "\n",
    "conv1 = Convolution2D(16, 3, 3, activation='relu', border_mode='same') # create the layer instance that i want to tie to\n",
    "c1 = conv1(input_img) # then call the layer\n",
    "m1 = MaxPooling2D((2, 2), border_mode='same')(c1)\n",
    "\n",
    "c2 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(m1)\n",
    "u1 = UpSampling2D((2, 2))(c2)\n",
    "d1 = Convolution2D_tied(1, 3, 3, activation='sigmoid', border_mode='same', tied_to=conv1)(u1) # now this layer is tied to conv1\n",
    "\n",
    "# and compile as usual\n",
    "autoencoder = Model(input_img, d1)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
