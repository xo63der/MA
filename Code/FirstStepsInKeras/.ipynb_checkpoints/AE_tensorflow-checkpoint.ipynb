{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:383: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:385: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:387: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Conv2D' object has no attribute 'nb_row'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0e00a8b4c8a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[0mc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[0mu1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m \u001b[0md1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvolution2D_tied\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtied_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# now this layer is tied to conv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;31m# and compile as usual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-0e00a8b4c8a3>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, nb_filter, nb_row, nb_col, init, activation, weights, border_mode, subsample, dim_ordering, W_regularizer, b_regularizer, activity_regularizer, W_constraint, b_constraint, bias, tied_to, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtied_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtied_to\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_filter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtied_to\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_row\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtied_to\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_col\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Conv2D' object has no attribute 'nb_row'"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   mnist_ae1.py   date. 7/4/2016\n",
    "#   \n",
    "#   Autoencoder tutorial code\n",
    "#\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Variables\n",
    "x = tf.placeholder(\"float\", [None, 784])\n",
    "y_ = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "w_enc = tf.Variable(tf.random_normal([784, 625], mean=0.0, stddev=0.05))\n",
    "w_dec = tf.Variable(tf.random_normal([625, 784], mean=0.0, stddev=0.05))\n",
    "# w_dec = tf.transpose(w_enc) # if you use tied weights\n",
    "b_enc = tf.Variable(tf.zeros([625]))\n",
    "b_dec = tf.Variable(tf.zeros([784]))\n",
    "\n",
    "# Create the model\n",
    "def model(X, w_e, b_e, w_d, b_d):\n",
    "    encoded = tf.sigmoid(tf.matmul(X, w_e) + b_e)\n",
    "    decoded = tf.sigmoid(tf.matmul(encoded, w_d) + b_d)\n",
    "    \n",
    "    return encoded, decoded\n",
    "\n",
    "encoded, decoded = model(x, w_enc, b_enc, w_dec, b_dec)\n",
    "\n",
    "# Cost Function basic term\n",
    "cross_entropy = -1. * x * tf.log(decoded) - (1. - x) * tf.log(1. - decoded)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "train_step = tf.train.AdagradOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# Train\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('Training...')\n",
    "    for i in range(10001):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(128)\n",
    "        train_step.run({x: batch_xs, y_: batch_ys})\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            train_loss = loss.eval({x: batch_xs, y_: batch_ys})\n",
    "            print('  step, loss = %6d: %6.3f' % (i, train_loss))\n",
    "        \n",
    "    # generate decoded image with test data\n",
    "    test_fd = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "    decoded_imgs = decoded.eval(test_fd)\n",
    "    print('loss (test) = ', loss.eval(test_fd))\n",
    "    \n",
    "x_test = mnist.test.images\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.savefig('mnist_ae1.png')\n",
    "\n",
    " mnist_ae2.py\n",
    "#\n",
    "#   mnist_ae2.py   date. 7/4/2016\n",
    "#   \n",
    "#   Autoencoder tutorial code - trial of convolutional AE\n",
    "#\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from my_nn_lib import Convolution2D, MaxPooling2D\n",
    "from my_nn_lib import FullConnected, ReadOutLayer\n",
    "\n",
    "# Up-sampling 2-D Layer (deconvolutoinal Layer)\n",
    "class Conv2Dtranspose(object):\n",
    "    '''\n",
    "      constructor's args:\n",
    "          input      : input image (2D matrix)\n",
    "          output_siz : output image size\n",
    "          in_ch      : number of incoming image channel\n",
    "          out_ch     : number of outgoing image channel\n",
    "          patch_siz  : filter(patch) size\n",
    "    '''\n",
    "    def __init__(self, input, output_siz, in_ch, out_ch, patch_siz, activation='relu'):\n",
    "        self.input = input      \n",
    "        self.rows = output_siz[0]\n",
    "        self.cols = output_siz[1]\n",
    "        self.out_ch = out_ch\n",
    "        self.activation = activation\n",
    "        \n",
    "        wshape = [patch_siz[0], patch_siz[1], out_ch, in_ch]    # note the arguments order\n",
    "        \n",
    "        w_cvt = tf.Variable(tf.truncated_normal(wshape, stddev=0.1), \n",
    "                            trainable=True)\n",
    "        b_cvt = tf.Variable(tf.constant(0.1, shape=[out_ch]), \n",
    "                            trainable=True)\n",
    "        self.batsiz = tf.shape(input)[0]\n",
    "        self.w = w_cvt\n",
    "        self.b = b_cvt\n",
    "        self.params = [self.w, self.b]\n",
    "        \n",
    "    def output(self):\n",
    "        shape4D = [self.batsiz, self.rows, self.cols, self.out_ch]      \n",
    "        linout = tf.nn.conv2d_transpose(self.input, self.w, output_shape=shape4D,\n",
    "                            strides=[1, 2, 2, 1], padding='SAME') + self.b\n",
    "        if self.activation == 'relu':\n",
    "            self.output = tf.nn.relu(linout)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.output = tf.sigmoid(linout)\n",
    "        else:\n",
    "            self.output = linout\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "# Create the model\n",
    "def model(X, w_e, b_e, w_d, b_d):\n",
    "    encoded = tf.sigmoid(tf.matmul(X, w_e) + b_e)\n",
    "    decoded = tf.sigmoid(tf.matmul(encoded, w_d) + b_d)\n",
    "    \n",
    "    return encoded, decoded\n",
    "\n",
    "def mk_nn_model(x, y_):\n",
    "    # Encoding phase\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])    \n",
    "    conv1 = Convolution2D(x_image, (28, 28), 1, 16, \n",
    "                          (3, 3), activation='relu')\n",
    "    conv1_out = conv1.output()\n",
    "    \n",
    "    pool1 = MaxPooling2D(conv1_out)\n",
    "    pool1_out = pool1.output()\n",
    "    \n",
    "    conv2 = Convolution2D(pool1_out, (14, 14), 16, 8, \n",
    "                          (3, 3), activation='relu')\n",
    "    conv2_out = conv2.output()\n",
    "    \n",
    "    pool2 = MaxPooling2D(conv2_out)\n",
    "    pool2_out = pool2.output()\n",
    "\n",
    "    conv3 = Convolution2D(pool2_out, (7, 7), 8, 8, (3, 3), activation='relu')\n",
    "    conv3_out = conv3.output()\n",
    "\n",
    "    pool3 = MaxPooling2D(conv3_out)\n",
    "    pool3_out = pool3.output()\n",
    "    # at this point the representation is (8, 4, 4) i.e. 128-dimensional\n",
    "    # Decoding phase\n",
    "    conv_t1 = Conv2Dtranspose(pool3_out, (7, 7), 8, 8,\n",
    "                         (3, 3), activation='relu')\n",
    "    conv_t1_out = conv_t1.output()\n",
    "\n",
    "    conv_t2 = Conv2Dtranspose(conv_t1_out, (14, 14), 8, 8,\n",
    "                         (3, 3), activation='relu')\n",
    "    conv_t2_out = conv_t2.output()\n",
    "\n",
    "    conv_t3 = Conv2Dtranspose(conv_t2_out, (28, 28), 8, 16, \n",
    "                         (3, 3), activation='relu')\n",
    "    conv_t3_out = conv_t3.output()\n",
    "\n",
    "    conv_last = Convolution2D(conv_t3_out, (28, 28), 16, 1, (3, 3),\n",
    "                         activation='sigmoid')\n",
    "    decoded = conv_last.output()\n",
    "\n",
    "    decoded = tf.reshape(decoded, [-1, 784])\n",
    "    cross_entropy = -1. *x *tf.log(decoded) - (1. - x) *tf.log(1. - decoded)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "       \n",
    "    return loss, decoded\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)\n",
    "    # Variables\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10]) \n",
    "\n",
    "    loss, decoded = mk_nn_model(x, y_)\n",
    "    train_step = tf.train.AdagradOptimizer(0.1).minimize(loss)\n",
    "\n",
    "    init = tf.initialize_all_variables()\n",
    "    # Train\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        print('Training...')\n",
    "        for i in range(10001):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(128)\n",
    "            train_step.run({x: batch_xs, y_: batch_ys})\n",
    "            if i % 1000 == 0:\n",
    "                train_loss= loss.eval({x: batch_xs, y_: batch_ys})\n",
    "                print('  step, loss = %6d: %6.3f' % (i, train_loss))\n",
    "\n",
    "        # generate decoded image with test data\n",
    "        test_fd = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "        decoded_imgs = decoded.eval(test_fd)\n",
    "        print('loss (test) = ', loss.eval(test_fd))\n",
    "     \n",
    "    x_test = mnist.test.images\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    #plt.show()\n",
    "    plt.savefig('mnist_ae2.png')\n",
    "    \n",
    "#\n",
    "#   my_nn_lib.py\n",
    "#       date. 5/19/2016\n",
    "#\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "# import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Convolution 2-D Layer\n",
    "class Convolution2D(object):\n",
    "    '''\n",
    "      constructor's args:\n",
    "          input     : input image (2D matrix)\n",
    "          input_siz ; input image size\n",
    "          in_ch     : number of incoming image channel\n",
    "          out_ch    : number of outgoing image channel\n",
    "          patch_siz : filter(patch) size\n",
    "          weights   : (if input) (weights, bias)\n",
    "    '''\n",
    "    def __init__(self, input, input_siz, in_ch, out_ch, patch_siz, activation='relu'):\n",
    "        self.input = input      \n",
    "        self.rows = input_siz[0]\n",
    "        self.cols = input_siz[1]\n",
    "        self.in_ch = in_ch\n",
    "        self.activation = activation\n",
    "        \n",
    "        wshape = [patch_siz[0], patch_siz[1], in_ch, out_ch]\n",
    "        \n",
    "        w_cv = tf.Variable(tf.truncated_normal(wshape, stddev=0.1), \n",
    "                            trainable=True)\n",
    "        b_cv = tf.Variable(tf.constant(0.1, shape=[out_ch]), \n",
    "                            trainable=True)\n",
    "        \n",
    "        self.w = w_cv\n",
    "        self.b = b_cv\n",
    "        self.params = [self.w, self.b]\n",
    "        \n",
    "    def output(self):\n",
    "        shape4D = [-1, self.rows, self.cols, self.in_ch]\n",
    "        \n",
    "        x_image = tf.reshape(self.input, shape4D)  # reshape to 4D tensor\n",
    "        linout = tf.nn.conv2d(x_image, self.w, \n",
    "                  strides=[1, 1, 1, 1], padding='SAME') + self.b\n",
    "        if self.activation == 'relu':\n",
    "            self.output = tf.nn.relu(linout)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            self.output = tf.sigmoid(linout)\n",
    "        else:\n",
    "            self.output = linout\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "# Max Pooling Layer   \n",
    "class MaxPooling2D(object):\n",
    "    '''\n",
    "      constructor's args:\n",
    "          input  : input image (2D matrix)\n",
    "          ksize  : pooling patch size\n",
    "    '''\n",
    "    def __init__(self, input, ksize=None):\n",
    "        self.input = input\n",
    "        if ksize == None:\n",
    "            ksize = [1, 2, 2, 1]\n",
    "            self.ksize = ksize\n",
    "    \n",
    "    def output(self):\n",
    "        self.output = tf.nn.max_pool(self.input, ksize=self.ksize,\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "  \n",
    "        return self.output\n",
    "\n",
    "# Full-connected Layer   \n",
    "class FullConnected(object):\n",
    "    def __init__(self, input, n_in, n_out):\n",
    "        self.input = input\n",
    "    \n",
    "        w_h = tf.Variable(tf.truncated_normal([n_in,n_out],\n",
    "                          mean=0.0, stddev=0.05), trainable=True)\n",
    "        b_h = tf.Variable(tf.zeros([n_out]), trainable=True)\n",
    "     \n",
    "        self.w = w_h\n",
    "        self.b = b_h\n",
    "        self.params = [self.w, self.b]\n",
    "    \n",
    "    def output(self):\n",
    "        linarg = tf.matmul(self.input, self.w) + self.b\n",
    "        self.output = tf.nn.relu(linarg)\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "# Read-out Layer\n",
    "class ReadOutLayer(object):\n",
    "    def __init__(self, input, n_in, n_out):\n",
    "        self.input = input\n",
    "        \n",
    "        w_o = tf.Variable(tf.random_normal([n_in,n_out],\n",
    "                        mean=0.0, stddev=0.05), trainable=True)\n",
    "        b_o = tf.Variable(tf.zeros([n_out]), trainable=True)\n",
    "       \n",
    "        self.w = w_o\n",
    "        self.b = b_o\n",
    "        self.params = [self.w, self.b]\n",
    "    \n",
    "    def output(self):\n",
    "        linarg = tf.matmul(self.input, self.w) + self.b\n",
    "        self.output = tf.nn.softmax(linarg)  \n",
    "\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
