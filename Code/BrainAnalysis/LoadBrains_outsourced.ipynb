{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###### %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# convolutional autoencoder in keras\n",
    "\n",
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist \n",
    "\n",
    "from scipy.ndimage.filters import gaussian_laplace\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nilearn\n",
    "from nilearn import plotting\n",
    "\n",
    "import brain_functions as bf\n",
    "\n",
    "#from PIL import Image\n",
    "\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create input\n",
    "\n",
    "size=21\n",
    "\n",
    "train_path = \"C:/Users/A2/Documents/CDS/MA/MA/test_pics/\"\n",
    "test_path = \"C:/Users/A2/Documents/CDS/MA/MA/test_pics/\"\n",
    "\n",
    "#train_path = \"/home/hoffmann/MRI/training_data/\"\n",
    "#test_path = \"/home/hoffmann/MRI/test_data/\"\n",
    "\n",
    "#bf.show_skull(test_path)\n",
    "\n",
    "train_batches, train_allpos, train_vip=bf.loadbatches(test_path, size)\n",
    "test_batches, test_allpos, test_vip=bf.loadbatches(test_path, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxfil=32\n",
    "bs_z=2\n",
    "eps=2\n",
    "    \n",
    "name='testspeicher'\n",
    "    \n",
    "#bf.pretrain(train_batches,test_batches,name,size,maxfil,bs_z,eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder, encoder = bf.unrollAndTrain(train_batches,test_batches,name,size,maxfil,bs_z,eps)\n",
    "autoencoder, encoder = bf.loadAutoencoder(name,size,maxfil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 21, 21, 21, 1)\n",
      "(87, 7, 7, 7, 8)\n"
     ]
    }
   ],
   "source": [
    "encoded_imgs = encoder.predict(test_batches)\n",
    "print(np.shape(test_batches))\n",
    "print(np.shape(encoded_imgs))\n",
    "\n",
    "#bf.show_batch(test_batches, size, autoencoder.predict(test_batches))\n",
    "#bf.show_encoded(test_batches, size, encoded_imgs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-45ab9c444705>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_fil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetMaxGrads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxfil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m't4c1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mshow_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_fil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\CDS\\MA\\MA\\Code\\BrainAnalysis\\brain_functions.py\u001b[0m in \u001b[0;36mgetMaxGrads\u001b[1;34m(input_set, name, size, maxfil, layer_name)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0miterate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out, out_fil = bf.getMaxGrads(test_batches, name, size, maxfil, 't4c1')\n",
    "bf.show_batch(test_batches, size, out)\n",
    "bf.show_batch(test_batches, size, out_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk\n",
    "\n",
    "reader1 = itk.ImageFileReader.IUC2.New(FileName=train_path+\"/sub-032367_ses-01_acq-mp2rage_brain.nii.gz\")\n",
    "image1  = reader1.GetOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=0.000001\n",
    "\n",
    "mean_act=[]\n",
    "mean_act.append(np.full((maxfil),init))\n",
    "mean_act.append(np.full(1,init))\n",
    "mean_act.append(np.full((int(maxfil/2)),init))\n",
    "mean_act.append(np.full((int(maxfil/4)),init))\n",
    "mean_act.append(np.full((int(maxfil/4)),init))\n",
    "mean_act.append(np.full((int(maxfil/2)),init))\n",
    "mean_act.append(np.full((maxfil),init))\n",
    "mean_act.append(np.full(1,init))\n",
    "\n",
    "i = -1\n",
    "j = -1\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "def calc_mean(a_tensor):\n",
    "    global i\n",
    "    global j\n",
    "    global mean_act\n",
    "    \n",
    "    if j == 1:\n",
    "        j=-1\n",
    "    \n",
    "    j+=1\n",
    "    i+=1\n",
    "    \n",
    "    ### x is 21x21x21xnof tensor -> combine to nof tensor (mean of all 21x21x21 activations?)\n",
    "    \n",
    "    #x=K.eval(a_tensor)\n",
    "      \n",
    "    for k in range(K.int_shape(a_tensor)[-1]):\n",
    "        mean_act[j][k]=mean_act[j][k]*i/(i+1)+K.mean(a_tensor[:,:,:,:,k])\n",
    "    return mean_act[j]\n",
    "\n",
    "def kl_divergence(p, p_hat):\n",
    "    return (p * K.log(p/p_hat)) + ((1-p) * K.log((1-p)/(1-p_hat)))\n",
    "\n",
    "def kl_reg(x):\n",
    "    beta=0.1\n",
    "    p=0.001\n",
    "    p_hat=calc_mean(x)\n",
    "    res=0\n",
    "    for i in range(len(K.int_shape(p_hat))):\n",
    "        res+=kl_divergence(p,p_hat[i])\n",
    "    \n",
    "    return beta * res / K.int_shape(p_hat)\n",
    "\n",
    "test2_c1=Conv3D(maxfil, (3, 3, 3), activation='sigmoid', padding='same', name='t1c1', activity_regularizer=kl_reg)(input_img)\n",
    "test2_decoded=Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same', name='t1tc1', activity_regularizer=kl_reg)(test2_c1)\n",
    "    \n",
    "test2_autoencoder = Model(input_img, test2_decoded)\n",
    "test2_autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "test2_autoencoder.fit(train_batches, train_batches, \n",
    "                     validation_data=(test_batches, test_batches),\n",
    "                     epochs=2, batch_size=bs_z, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_act[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init=0.000001\n",
    "\n",
    "mean_act=[]\n",
    "mean_act.append(np.full((maxfil),init))\n",
    "mean_act.append(np.full(1,init))\n",
    "mean_act.append(np.full((int(maxfil/2)),init))\n",
    "mean_act.append(np.full((int(maxfil/4)),init))\n",
    "mean_act.append(np.full((int(maxfil/4)),init))\n",
    "mean_act.append(np.full((int(maxfil/2)),init))\n",
    "mean_act.append(np.full((maxfil),init))\n",
    "mean_act.append(np.full(1,init))\n",
    "\n",
    "d\n",
    "\n",
    "i = -1\n",
    "j = -1\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "def calc_mean(a_tensor):\n",
    "    global i\n",
    "    global j\n",
    "    global mean_act\n",
    "    \n",
    "    if j == 1:\n",
    "        j=-1\n",
    "    \n",
    "    j+=1\n",
    "    i+=1\n",
    "    \n",
    "    ### x is 21x21x21xnof tensor -> combine to nof tensor (mean of all 21x21x21 activations?)\n",
    "    \n",
    "    #x=K.eval(a_tensor)\n",
    "    \n",
    "    x=K.mean(a_tensor, axis=[1,2,3])\n",
    "    \n",
    "    global d\n",
    "    d=K.int_shape(x)\n",
    "    \n",
    "    mean_act[j]=mean_act[j]*i/(i+1)+x\n",
    "    return mean_act[j]\n",
    "\n",
    "def kl_divergence(p, p_hat):\n",
    "    return (p * np.log(p/p_hat)) + ((1-p) * np.log((1-p)/(1-p_hat)))\n",
    "\n",
    "def kl_reg(x):\n",
    "    beta=0.1\n",
    "    p=0.001\n",
    "    p_hat=calc_mean(x)\n",
    "    res=0\n",
    "    for i in range(len(p_hat)):\n",
    "        res+=kl_divergence(p,p_hat[i])\n",
    "    print(beta * res / len(p_hat))\n",
    "    \n",
    "    return beta * res / len(p_hat)\n",
    "\n",
    "test2_c1=Conv3D(maxfil, (3, 3, 3), activation='sigmoid', padding='same', name='t1c1', activity_regularizer=kl_reg)(input_img)\n",
    "test2_decoded=Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same', name='t1tc1', activity_regularizer=kl_reg)(test2_c1)\n",
    "    \n",
    "test2_autoencoder = Model(input_img, test2_decoded)\n",
    "test2_autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "test2_autoencoder.fit(train_batches, train_batches, \n",
    "                     validation_data=(test_batches, test_batches),\n",
    "                     epochs=2, batch_size=bs_z, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activeKL(model):\n",
    "    \n",
    "    add_loss=0\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    \n",
    "    for l in layer_dict:\n",
    "        print(l.name)\n",
    "        nof=l.output_shape[4]\n",
    "        for i in nof:\n",
    "            q_hat=K.mean(l.output[:, :, :, :, i])\n",
    "            loss+=kl_divergence(0.001,q_hat)\n",
    "    \n",
    "    return loss*0.1\n",
    "\n",
    "def own_mean_squared_error(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "def own_loss(y_true, y_pred):\n",
    "    return own_mean_squared_error(y_true, y_pred)+activeKL\n",
    "\n",
    "def kl_divergence(p, p_hat):\n",
    "    return (p * K.log(p / p_hat)) + ((1-p) * K.log((1-p) / (1-p_hat)))\n",
    "\n",
    "test2_c1=Conv3D(maxfil, (3, 3, 3), activation='sigmoid', padding='same', name='t1c1', activity_regularizer=l1_reg)(input_img)\n",
    "test2_decoded=Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same', name='t1tc1', activity_regularizer=l1_reg)(test2_c1)\n",
    "    \n",
    "test2_autoencoder = Model(input_img, test2_decoded)\n",
    "test2_autoencoder.compile(optimizer='adadelta', loss=own_loss)\n",
    "\n",
    "test2_autoencoder.fit(train_batches, train_batches, \n",
    "                     validation_data=(test_batches, test_batches),\n",
    "                     epochs=2, batch_size=bs_z, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import Regularizer\n",
    "\n",
    "def kl_divergence(p, p_hat):\n",
    "    return (p * K.log(p / p_hat)) + ((1-p) * K.log((1-p) / (1-p_hat)))\n",
    "\n",
    "class SparseActivityRegularizer(Regularizer):\n",
    "    sparsityBeta = None\n",
    "\n",
    "    def __init__(self, l1=0., l2=0., p=0.001, sparsityBeta=0.1):\n",
    "        self.p = p\n",
    "        self.sparsityBeta = sparsityBeta\n",
    "\n",
    "    def set_layer(self, layer):\n",
    "        self.layer = layer\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        #p_hat needs to be the average activation of the units in the hidden layer.      \n",
    "        p_hat = K.sum(K.mean(self.layer.get_output(True) , axis=0))\n",
    "\n",
    "        loss += self.sparsityBeta * kl_divergence(self.p, p_hat)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"name\": self.__class__.__name__,\"p\": self.l1}\n",
    "\n",
    "test_c1=Conv3D(maxfil, (3, 3, 3), activation='sigmoid', padding='same', name='t1c1', activity_regularizer=SparseActivityRegularizer(p=0.001, sparsityBeta=0.1))(input_img)\n",
    "test_decoded=Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same', name='t1tc1', activity_regularizer=SparseActivityRegularizer(p=0.001, sparsityBeta=0.1))(test_c1)\n",
    "    \n",
    "test_autoencoder = Model(input_img, test_decoded)\n",
    "test_autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "test_autoencoder.fit(train_batches, train_batches, \n",
    "                     validation_data=(test_batches, test_batches),\n",
    "                     epochs=eps, batch_size=bs_z, verbose=1)\n",
    "    \n",
    "'''\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "\n",
    "autoencoder = Sequential()\n",
    "encoder = containers.Sequential([Dense(250, input_dim=576, init='glorot_uniform', activation='tanh', \n",
    "    activity_regularizer=SparseActivityRegularizer(p=-0.9, sparsityBeta=0.1))])\n",
    "\n",
    "decoder = containers.Sequential([Dense(576, input_dim=250)])\n",
    "autoencoder.add(AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=True))\n",
    "autoencoder.layers[0].build()\n",
    "autoencoder.compile(loss='mse', optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True))\n",
    "loss = autoencoder.fit(X_train_tmp, X_train_tmp, nb_epoch=200, batch_size=800, verbose=True, show_accuracy=True, validation_split = 0.3)\n",
    "autoencoder.save_weights('SparseAutoEncoder.h5',overwrite = True)\n",
    "result = autoencoder.predict(X_test)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
