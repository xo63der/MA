{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###### %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# convolutional autoencoder in keras\n",
    "\n",
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist \n",
    "\n",
    "from scipy.ndimage.filters import gaussian_laplace\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nilearn\n",
    "from nilearn import plotting\n",
    "\n",
    "import brain_functions as bf\n",
    "\n",
    "#from PIL import Image\n",
    "\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create input\n",
    "\n",
    "size=21\n",
    "\n",
    "train_path = \"C:/Users/A2/Documents/CDS/MA/MA/test_pics/\"\n",
    "test_path = \"C:/Users/A2/Documents/CDS/MA/MA/test_pics/\"\n",
    "\n",
    "#train_path = \"/home/hoffmann/MRI/training_data/\"\n",
    "#test_path = \"/home/hoffmann/MRI/test_data/\"\n",
    "\n",
    "#bf.show_skull(test_path)\n",
    "\n",
    "train_batches, train_allpos, train_vip=bf.loadbatches(test_path, size)\n",
    "test_batches, test_allpos, test_vip=bf.loadbatches(test_path, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "maxfil=32\n",
    "bs_z=2\n",
    "eps=2\n",
    "    \n",
    "name='testspeicher'\n",
    "    \n",
    "#bf.pretrain(train_batches,test_batches,name,size,maxfil,bs_z,eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = bf.unrollAndTrain(train_batches,test_batches,name,size,maxfil,bs_z,eps)\n",
    "\n",
    "bf.show_batch(test_batches, size, autoencoder.predict(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(test_batches)\n",
    "\n",
    "print(np.shape(encoded_imgs))\n",
    "\n",
    "bf.show_hidden(test_batches, size, encoded_imgs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out, out_fil = bf.getMaxGrads(test_batches, autoencoder, 't4c1', int(maxfil/4))\n",
    "bf.show_batch(test_batches, size, out)\n",
    "show_batch(test_batches, size, out_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk\n",
    "\n",
    "reader1 = itk.ImageFileReader.IUC2.New(FileName=train_path+\"/sub-032367_ses-01_acq-mp2rage_brain.nii.gz\")\n",
    "image1  = reader1.GetOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=0.000001\n",
    "\n",
    "mean_act=[]\n",
    "mean_act.append(np.full((maxfil),init))\n",
    "mean_act.append(np.full(1,init))\n",
    "mean_act.append(np.full((int(maxfil/2)),init))\n",
    "mean_act.append(np.full((int(maxfil/4)),init))\n",
    "mean_act.append(np.full((int(maxfil/4)),init))\n",
    "mean_act.append(np.full((int(maxfil/2)),init))\n",
    "mean_act.append(np.full((maxfil),init))\n",
    "mean_act.append(np.full(1,init))\n",
    "\n",
    "i = -1\n",
    "j = -1\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "def calc_mean(a_tensor):\n",
    "    global i\n",
    "    global j\n",
    "    global mean_act\n",
    "    \n",
    "    if j == 1:\n",
    "        j=-1\n",
    "    \n",
    "    j+=1\n",
    "    i+=1\n",
    "    \n",
    "    ### x is 21x21x21xnof tensor -> combine to nof tensor (mean of all 21x21x21 activations?)\n",
    "    \n",
    "    #x=K.eval(a_tensor)\n",
    "      \n",
    "    for k in range(K.int_shape(a_tensor)[-1]):\n",
    "        mean_act[j][k]=mean_act[j][k]*i/(i+1)+K.mean(a_tensor[:,:,:,:,k])\n",
    "    return mean_act[j]\n",
    "\n",
    "def kl_divergence(p, p_hat):\n",
    "    return (p * K.log(p/p_hat)) + ((1-p) * K.log((1-p)/(1-p_hat)))\n",
    "\n",
    "def kl_reg(x):\n",
    "    beta=0.1\n",
    "    p=0.001\n",
    "    p_hat=calc_mean(x)\n",
    "    res=0\n",
    "    for i in range(len(K.int_shape(p_hat))):\n",
    "        res+=kl_divergence(p,p_hat[i])\n",
    "    \n",
    "    return beta * res / K.int_shape(p_hat)\n",
    "\n",
    "test2_c1=Conv3D(maxfil, (3, 3, 3), activation='sigmoid', padding='same', name='t1c1', activity_regularizer=kl_reg)(input_img)\n",
    "test2_decoded=Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same', name='t1tc1', activity_regularizer=kl_reg)(test2_c1)\n",
    "    \n",
    "test2_autoencoder = Model(input_img, test2_decoded)\n",
    "test2_autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "test2_autoencoder.fit(train_batches, train_batches, \n",
    "                     validation_data=(test_batches, test_batches),\n",
    "                     epochs=2, batch_size=bs_z, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_act[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init=0.000001\n",
    "\n",
    "mean_act=[]\n",
    "mean_act.append(np.full((maxfil),init))\n",
    "mean_act.append(np.full(1,init))\n",
    "mean_act.append(np.full((int(maxfil/2)),init))\n",
    "mean_act.append(np.full((int(maxfil/4)),init))\n",
    "mean_act.append(np.full((int(maxfil/4)),init))\n",
    "mean_act.append(np.full((int(maxfil/2)),init))\n",
    "mean_act.append(np.full((maxfil),init))\n",
    "mean_act.append(np.full(1,init))\n",
    "\n",
    "d\n",
    "\n",
    "i = -1\n",
    "j = -1\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "def calc_mean(a_tensor):\n",
    "    global i\n",
    "    global j\n",
    "    global mean_act\n",
    "    \n",
    "    if j == 1:\n",
    "        j=-1\n",
    "    \n",
    "    j+=1\n",
    "    i+=1\n",
    "    \n",
    "    ### x is 21x21x21xnof tensor -> combine to nof tensor (mean of all 21x21x21 activations?)\n",
    "    \n",
    "    #x=K.eval(a_tensor)\n",
    "    \n",
    "    x=K.mean(a_tensor, axis=[1,2,3])\n",
    "    \n",
    "    global d\n",
    "    d=K.int_shape(x)\n",
    "    \n",
    "    mean_act[j]=mean_act[j]*i/(i+1)+x\n",
    "    return mean_act[j]\n",
    "\n",
    "def kl_divergence(p, p_hat):\n",
    "    return (p * np.log(p/p_hat)) + ((1-p) * np.log((1-p)/(1-p_hat)))\n",
    "\n",
    "def kl_reg(x):\n",
    "    beta=0.1\n",
    "    p=0.001\n",
    "    p_hat=calc_mean(x)\n",
    "    res=0\n",
    "    for i in range(len(p_hat)):\n",
    "        res+=kl_divergence(p,p_hat[i])\n",
    "    print(beta * res / len(p_hat))\n",
    "    \n",
    "    return beta * res / len(p_hat)\n",
    "\n",
    "test2_c1=Conv3D(maxfil, (3, 3, 3), activation='sigmoid', padding='same', name='t1c1', activity_regularizer=kl_reg)(input_img)\n",
    "test2_decoded=Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same', name='t1tc1', activity_regularizer=kl_reg)(test2_c1)\n",
    "    \n",
    "test2_autoencoder = Model(input_img, test2_decoded)\n",
    "test2_autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "test2_autoencoder.fit(train_batches, train_batches, \n",
    "                     validation_data=(test_batches, test_batches),\n",
    "                     epochs=2, batch_size=bs_z, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activeKL(model):\n",
    "    \n",
    "    add_loss=0\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    \n",
    "    for l in layer_dict:\n",
    "        print(l.name)\n",
    "        nof=l.output_shape[4]\n",
    "        for i in nof:\n",
    "            q_hat=K.mean(l.output[:, :, :, :, i])\n",
    "            loss+=kl_divergence(0.001,q_hat)\n",
    "    \n",
    "    return loss*0.1\n",
    "\n",
    "def own_mean_squared_error(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "def own_loss(y_true, y_pred):\n",
    "    return own_mean_squared_error(y_true, y_pred)+activeKL\n",
    "\n",
    "def kl_divergence(p, p_hat):\n",
    "    return (p * K.log(p / p_hat)) + ((1-p) * K.log((1-p) / (1-p_hat)))\n",
    "\n",
    "test2_c1=Conv3D(maxfil, (3, 3, 3), activation='sigmoid', padding='same', name='t1c1', activity_regularizer=l1_reg)(input_img)\n",
    "test2_decoded=Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same', name='t1tc1', activity_regularizer=l1_reg)(test2_c1)\n",
    "    \n",
    "test2_autoencoder = Model(input_img, test2_decoded)\n",
    "test2_autoencoder.compile(optimizer='adadelta', loss=own_loss)\n",
    "\n",
    "test2_autoencoder.fit(train_batches, train_batches, \n",
    "                     validation_data=(test_batches, test_batches),\n",
    "                     epochs=2, batch_size=bs_z, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import Regularizer\n",
    "\n",
    "def kl_divergence(p, p_hat):\n",
    "    return (p * K.log(p / p_hat)) + ((1-p) * K.log((1-p) / (1-p_hat)))\n",
    "\n",
    "class SparseActivityRegularizer(Regularizer):\n",
    "    sparsityBeta = None\n",
    "\n",
    "    def __init__(self, l1=0., l2=0., p=0.001, sparsityBeta=0.1):\n",
    "        self.p = p\n",
    "        self.sparsityBeta = sparsityBeta\n",
    "\n",
    "    def set_layer(self, layer):\n",
    "        self.layer = layer\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        #p_hat needs to be the average activation of the units in the hidden layer.      \n",
    "        p_hat = K.sum(K.mean(self.layer.get_output(True) , axis=0))\n",
    "\n",
    "        loss += self.sparsityBeta * kl_divergence(self.p, p_hat)\n",
    "        return loss\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"name\": self.__class__.__name__,\"p\": self.l1}\n",
    "\n",
    "test_c1=Conv3D(maxfil, (3, 3, 3), activation='sigmoid', padding='same', name='t1c1', activity_regularizer=SparseActivityRegularizer(p=0.001, sparsityBeta=0.1))(input_img)\n",
    "test_decoded=Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same', name='t1tc1', activity_regularizer=SparseActivityRegularizer(p=0.001, sparsityBeta=0.1))(test_c1)\n",
    "    \n",
    "test_autoencoder = Model(input_img, test_decoded)\n",
    "test_autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "test_autoencoder.fit(train_batches, train_batches, \n",
    "                     validation_data=(test_batches, test_batches),\n",
    "                     epochs=eps, batch_size=bs_z, verbose=1)\n",
    "    \n",
    "'''\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "\n",
    "autoencoder = Sequential()\n",
    "encoder = containers.Sequential([Dense(250, input_dim=576, init='glorot_uniform', activation='tanh', \n",
    "    activity_regularizer=SparseActivityRegularizer(p=-0.9, sparsityBeta=0.1))])\n",
    "\n",
    "decoder = containers.Sequential([Dense(576, input_dim=250)])\n",
    "autoencoder.add(AutoEncoder(encoder=encoder, decoder=decoder, output_reconstruction=True))\n",
    "autoencoder.layers[0].build()\n",
    "autoencoder.compile(loss='mse', optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True))\n",
    "loss = autoencoder.fit(X_train_tmp, X_train_tmp, nb_epoch=200, batch_size=800, verbose=True, show_accuracy=True, validation_split = 0.3)\n",
    "autoencoder.save_weights('SparseAutoEncoder.h5',overwrite = True)\n",
    "result = autoencoder.predict(X_test)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
