{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoffmann/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 845 images belonging to 1 classes.\n",
      "Found 37 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "###### %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# convolutional autoencoder in keras\n",
    "\n",
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# utility function for showing images\n",
    "def show_imgs(x_test, decoded_imgs, n=4):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(x_test[i].reshape(size,size))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        if decoded_imgs is not None:\n",
    "            ax = plt.subplot(2, n, i+ 1 +n)\n",
    "            plt.imshow(decoded_imgs[i].reshape(size,size))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "### Create input\n",
    "\n",
    "bs_z=4\n",
    "\n",
    "train_path = \"/home/hoffmann/MA/OIRDS_v1_0/train\"\n",
    "test_path = \"/home/hoffmann/MA/OIRDS_v1_0/test\"\n",
    "\n",
    "size=256\n",
    "\n",
    "train_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(train_path,target_size=(size,size),color_mode='grayscale',batch_size=bs_z, class_mode = 'input',shuffle=False)\n",
    "test_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,target_size=(size,size),color_mode='grayscale',batch_size=bs_z, class_mode = 'input',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "211/212 [============================>.] - ETA: 0s - loss: 0.0206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 548, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 525, in <lambda>\n",
      "    self.executor_fn = lambda _: ThreadPool(workers)\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 789, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 200, in __init__\n",
      "    self._result_handler.start()\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/threading.py\", line 846, in start\n",
      "    _start_new_thread(self._bootstrap, ())\n",
      "RuntimeError: can't start new thread\n",
      "\n",
      "Exception in thread Thread-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 548, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 525, in <lambda>\n",
      "    self.executor_fn = lambda _: ThreadPool(workers)\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 789, in __init__\n",
      "    Pool.__init__(self, processes, initializer, initargs)\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/multiprocessing/dummy/__init__.py\", line 48, in start\n",
      "    threading.Thread.start(self)\n",
      "  File \"/home/hoffmann/anaconda3/lib/python3.6/threading.py\", line 846, in start\n",
      "    _start_new_thread(self._bootstrap, ())\n",
      "RuntimeError: can't start new thread\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a88fd85d6210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrain1_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain1_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m### pretrain2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2248\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m                                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2250\u001b[0;31m                                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[1;32m   2251\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2252\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2384\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m                     raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### pretrain1\n",
    "    \n",
    "input_img = Input(shape=(size, size,1))\n",
    "\n",
    "train1_norm=BatchNormalization(axis=-1, name='t1n')(input_img)\n",
    "train1_c1 = Conv2D(32, (3, 3), activation='relu', padding='same', name='t1c1')(train1_norm)\n",
    "train1_decoded = Conv2DTranspose(1, (3, 3), activation='relu', padding='same', name='t1tc1')(train1_c1)\n",
    "\n",
    "train1_autoencoder = Model(input_img, train1_decoded)\n",
    "train1_autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "train1_autoencoder.fit_generator(train_batches, epochs=1, validation_data=test_batches, verbose=1)\n",
    "\n",
    "### pretrain2\n",
    "\n",
    "creator_train2 = Model(input_img, train1_c1)\n",
    "creator_train2.get_layer(\"t1c1\").set_weights(train1_autoencoder.get_layer('t1c1').get_weights())\n",
    "\n",
    "input_train2 = creator_train2.predict_generator(train_batches,210)\n",
    "\n",
    "print(input_train2.shape)\n",
    "\n",
    "#---\n",
    "\n",
    "input_img_train2 = Input(shape=(size, size, 32))\n",
    "train2_p1 = MaxPooling2D(pool_size=(2, 2), name='t2p1')(input_img_train2)\n",
    "train2_c1 = Conv2D(32, (3, 3), activation='relu', padding='same', name='t2c1')(train2_p1)\n",
    "train2_tc1 = Conv2DTranspose(32, (3, 3), activation='relu', padding='same', name='t2tc1')(train2_c1)\n",
    "train2_decoded = UpSampling2D(size=(2, 2), name='t3u1')(train2_tc1)\n",
    "\n",
    "train2_autoencoder = Model(input_img_train2, train2_decoded)\n",
    "train2_autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "train2_autoencoder.fit(input_train2, input_train2, epochs=1, batch_size=bs_z, verbose=1)\n",
    "\n",
    "### pretrain3\n",
    "\n",
    "creator_train3 = Model(input_img_train2, train2_c1)\n",
    "creator_train3.get_layer(\"t2c1\").set_weights(train2_autoencoder.get_layer('t2c1').get_weights())\n",
    "\n",
    "input_train3 = creator_train3.predict(input_train2)\n",
    "\n",
    "print(input_train3.shape)\n",
    "\n",
    "#---\n",
    "\n",
    "input_img_train3 = Input(shape=(size/2, size/2, 32))\n",
    "train3_p1 = MaxPooling2D(pool_size=(2, 2), name='t3p1')(input_img_train3)\n",
    "train3_c1 = Conv2D(16, (3, 3), activation='relu', padding='same', name='t3c1')(train3_p1)\n",
    "train3_tc1 = Conv2DTranspose(32, (3, 3), activation='relu', padding='same', name='t3tc1')(train3_c1)\n",
    "train3_decoded = UpSampling2D(size=(2, 2), name='t3u1')(train3_tc1)\n",
    "\n",
    "train3_autoencoder = Model(input_img_train3, train3_decoded)\n",
    "train3_autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "train3_autoencoder.fit(input_train3, input_train3, epochs=1, batch_size=bs_z, verbose=1)\n",
    "\n",
    "### pretrain4\n",
    "\n",
    "creator_train4 = Model(input_img_train3, train3_c1)\n",
    "creator_train4.get_layer(\"t3c1\").set_weights(train2_autoencoder.get_layer('t3c1').get_weights())\n",
    "\n",
    "input_train4 = creator_train4.predict(input_train3)\n",
    "\n",
    "print(input_train4.shape)\n",
    "\n",
    "#---\n",
    "\n",
    "input_img_train4 = Input(shape=(size/4, size/4, 16))\n",
    "train4_p1 = MaxPooling2D(pool_size=(2, 2), name='t4p1')(input_img_train4)\n",
    "train4_c1 = Conv2D(8, (3, 3), activation='relu', padding='same', name='t4c1')(train4_p1)\n",
    "train4_tc1 = Conv2DTranspose(16, (3, 3), activation='relu', padding='same', name='t4tc1')(train4_c1)\n",
    "train4_decoded = UpSampling2D(size=(2, 2), name='t4u1')(train4_tc1)\n",
    "\n",
    "train4_autoencoder = Model(input_img_train4, train4_decoded)\n",
    "train4_autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "train4_autoencoder.fit(input_train4, input_train4, epochs=1, batch_size=bs_z, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### unroll\n",
    "\n",
    "input_img = Input(shape=(size, size,1))\n",
    "\n",
    "norm=BatchNormalization(axis=-1, name='n', weights=train1_autoencoder.get_layer(\"t1n\").get_weights())(input_img)\n",
    "c1 = Conv2D(32, (3, 3), activation='relu', padding='same', name='c1', weights=train1_autoencoder.get_layer(\"t1c1\").get_weights())(norm)\n",
    "p1 = MaxPooling2D(pool_size=(2, 2), name='p1')(c1)\n",
    "c2 = Conv2D(32, (3, 3), activation='relu', padding='same', name='c2', weights=train2_autoencoder.get_layer(\"t2c1\").get_weights())(p1)\n",
    "p2 = MaxPooling2D(pool_size=(2, 2), name='p2')(c2)\n",
    "c3 = Conv2D(16, (3, 3), activation='relu', padding='same', name='c3', weights=train3_autoencoder.get_layer(\"t3c1\").get_weights())(p2)\n",
    "p3 = MaxPooling2D(pool_size=(2, 2), name='p3')(c3)\n",
    "encoded = Conv2D(8, (3, 3), activation='relu', padding='same', name='c4', weights=train4_autoencoder.get_layer(\"t4c1\").get_weights())(p3)\n",
    "tc4 = Conv2DTranspose(16, (3, 3), activation='relu', padding='same', name='tc4', weights=train4_autoencoder.get_layer(\"t4tc1\").get_weights())(encoded)\n",
    "u3 = UpSampling2D(size=(2, 2), name='u2')(tc4)\n",
    "tc3 = Conv2DTranspose(32, (3, 3), activation='relu', padding='same', name='tc3', weights=train3_autoencoder.get_layer(\"t3tc1\").get_weights())(u3)\n",
    "u2 = UpSampling2D(size=(2, 2), name='u2')(tc3)\n",
    "tc2 = Conv2DTranspose(32, (3, 3), activation='relu', padding='same', name='tc2', weights=train2_autoencoder.get_layer(\"t2tc1\").get_weights())(u2)\n",
    "u1 = UpSampling2D(size=(2, 2), name='u1')(tc2)\n",
    "decoded = Conv2DTranspose(1, (3, 3), activation='relu', padding='same', name='tc1', weights=train1_autoencoder.get_layer(\"t1tc1\").get_weights())(u1)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "### finetune\n",
    "\n",
    "autoencoder.fit_generator(train_batches, epochs=1, validation_data=test_batches, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('CAE_overhead_1ep_3pool_8f.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxGrads(input_set, model, layer_name, nof):\n",
    "    \n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    \n",
    "    out = np.zeros((len(input_set),len(input_set[0]),len(input_set[0][0])))\n",
    "\n",
    "    for i in range(nof):\n",
    "        filter_index = i  # can be any integer from 0 to 511, as there are 512 filters in that layer\n",
    "\n",
    "        layer_output = layer_dict[layer_name].output\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "        # compute the gradient of the input picture wrt this loss\n",
    "        grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "        #normalization trick: we normalize the gradient\n",
    "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)  ### normalize? ... later\n",
    "\n",
    "        # this function returns the loss and grads given the input picture\n",
    "        iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "        it = iterate([input_set])\n",
    "        \n",
    "        len1=len(out)\n",
    "        len2=len(out[0])\n",
    "        len3=len(out[0][0])\n",
    "        \n",
    "        for j in range(len1):\n",
    "            for k in range(len2):\n",
    "                for l in range(len3):\n",
    "                    if abs(it[1][j][k][l]) > out[j][k][l]:   #abs()?\n",
    "                        out[j][k][l]=abs(it[1][j][k][l])\n",
    "                        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = getMaxGrads(test_batches[0][0], autoencoder, 'c3', 8)\n",
    "\n",
    "a=len(test_batches[0][0])\n",
    "b=len(test_batches[0][0][0])\n",
    "c=len(test_batches[0][0][0][0])\n",
    "\n",
    "it_temp = np.zeros((a,b,c))\n",
    "\n",
    "    for i in range(a):\n",
    "        q = np.percentile(out[i],98)\n",
    "        for j in range(b):\n",
    "            for k in range(c):\n",
    "                if(out[i][j][k]>q):\n",
    "                    it_temp[i][j][k]=out[i][j][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writegrads = np.zeros((len(it_temp),len(it_temp[0])*len(it_temp[0])))\n",
    "\n",
    "for i in range(len(it_temp)):\n",
    "    temp = []\n",
    "    for j in it_temp[i]:\n",
    "        temp.extend(j)\n",
    "    writegrads[i] = temp\n",
    "\n",
    "np.savetxt('CAE_overhead_1ep_3pool_8f',writegrads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### plot\n",
    "\n",
    "decoded_imgs = autoencoder.predict_generator(test_batches)\n",
    "show_imgs(test_batches[0][0],decoded_imgs)\n",
    "\n",
    "print(autoencoder.summary())\n",
    "\n",
    "autoencoder_show_hidden = Model(input_img, encoded)\n",
    "encoded_imgs = autoencoder_show_hidden.predict_generator(test_batches)\n",
    "\n",
    "def show_hidden(x_test, encoded_imgs, n=10):\n",
    "    \n",
    "    en0=np.zeros((encoded_imgs.shape[0],encoded_imgs.shape[1],encoded_imgs.shape[2]))\n",
    "    en1=np.zeros((encoded_imgs.shape[0],encoded_imgs.shape[1],encoded_imgs.shape[2]))\n",
    "    en2=np.zeros((encoded_imgs.shape[0],encoded_imgs.shape[1],encoded_imgs.shape[2]))\n",
    "    en3=np.zeros((encoded_imgs.shape[0],encoded_imgs.shape[1],encoded_imgs.shape[2]))\n",
    "\n",
    "    for i in range(encoded_imgs.shape[0]):\n",
    "        for j in range(encoded_imgs.shape[1]):\n",
    "            for k in range(encoded_imgs.shape[2]):\n",
    "                en0[i][j][k]=encoded_imgs[i][j][k][0]\n",
    "                en1[i][j][k]=encoded_imgs[i][j][k][1]\n",
    "                en2[i][j][k]=encoded_imgs[i][j][k][2]\n",
    "                en3[i][j][k]=encoded_imgs[i][j][k][3]\n",
    "    \n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(5, n, i+1)\n",
    "        plt.imshow(x_test[i].reshape(size,size))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        if decoded_imgs is not None:\n",
    "            ax = plt.subplot(5, n, i+ 1 +n)\n",
    "            plt.imshow(en0[i].reshape(int(size/4),int(size/8)))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "            ax = plt.subplot(5, n, i+ 1 +2*n)\n",
    "            plt.imshow(en1[i].reshape(int(size/4),int(size/8)))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "            ax = plt.subplot(5, n, i+ 1 +3*n)\n",
    "            plt.imshow(en2[i].reshape(int(size/4),int(size/8)))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "            ax = plt.subplot(5, n, i+ 1 +4*n)\n",
    "            plt.imshow(en3[i].reshape(int(size/4),int(size/8)))\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "show_hidden(test_batches[0][0], encoded_imgs)\n",
    "\n",
    "#print grads\n",
    "\n",
    "show_imgs(test_batches[0][0],out)\n",
    "\n",
    "show_imgs(test_batches[0][0],it_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
